{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5172cb2-39c0-4d80-8201-f1424240e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5762c4ff-0ffd-49c3-a24b-c533d03f6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65005768-42a0-4726-9121-9917971d67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Bengaluru_House_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258c0b28-7d90-4ce2-b5ed-b2d8f507df9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              area_type   availability                  location       size  \\\n",
      "0  Super built-up  Area         19-Dec  Electronic City Phase II      2 BHK   \n",
      "1            Plot  Area  Ready To Move          Chikka Tirupathi  4 Bedroom   \n",
      "2        Built-up  Area  Ready To Move               Uttarahalli      3 BHK   \n",
      "3  Super built-up  Area  Ready To Move        Lingadheeranahalli      3 BHK   \n",
      "4  Super built-up  Area  Ready To Move                  Kothanur      2 BHK   \n",
      "\n",
      "   society total_sqft  bath  balcony   price  \n",
      "0  Coomee        1056   2.0      1.0   39.07  \n",
      "1  Theanmp       2600   5.0      3.0  120.00  \n",
      "2      NaN       1440   2.0      3.0   62.00  \n",
      "3  Soiewre       1521   3.0      1.0   95.00  \n",
      "4      NaN       1200   2.0      1.0   51.00  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8affc997-93b4-43c7-9174-41d141088dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 15528.364797772449\n",
      "Mean Absolute Error (MAE): 42.167011573429846\n",
      "R-squared (R^2) Score: 0.27064479449536316\n"
     ]
    }
   ],
   "source": [
    "#1. In order to predict house price based on several characteristics, such as location, square footage, number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this situation would be the best to employ?\n",
    "\n",
    "#Dataset link: https://drive.google.com/file/d/1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0/view?usp=share_link\n",
    "\n",
    "#Ans\n",
    "\n",
    "#In the context of predicting house prices based on multiple characteristics, there are several regression metrics you can consider to evaluate the performance of your SVM regression model. The choice of the best metric depends on the specific requirements and priorities of your problem. Here are a few commonly used regression metrics:\n",
    "\n",
    "#Mean Squared Error (MSE): MSE is a popular metric for regression tasks. It calculates the average squared difference between the predicted and true house prices. MSE gives higher weight to larger errors, which can be useful if you want to penalize large prediction errors more heavily.\n",
    "\n",
    "#Mean Absolute Error (MAE): MAE is another commonly used metric for regression evaluation. It computes the average absolute difference between the predicted and true house prices. Unlike MSE, MAE treats all errors equally and does not prioritize larger errors.\n",
    "\n",
    "#R-squared (R^2) Score: R^2 score measures the proportion of the variance in the dependent variable (house prices) that is predictable from the independent variables (characteristics). It ranges from 0 to 1, with higher values indicating a better fit of the model to the data. R^2 score can be useful to understand the percentage of the variability in house prices that can be explained by the model.\n",
    "\n",
    "#The choice of the best metric depends on your specific goals. If you want to minimize the impact of large errors, MSE can be suitable. If you prefer a metric that treats all errors equally, MAE might be a good choice. Additionally, R^2 score can provide insights into the overall goodness of fit of your model.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Bengaluru_House_Data.csv')\n",
    "\n",
    "# Drop irrelevant columns\n",
    "data = data.drop(['area_type', 'availability', 'society', 'balcony'], axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Split the data into numeric and categorical columns\n",
    "numeric_columns = data.select_dtypes(include='number').columns\n",
    "categorical_columns = data.select_dtypes(include='object').columns\n",
    "\n",
    "# Impute missing values in numeric columns\n",
    "data[numeric_columns] = numeric_imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "# Impute missing values in categorical columns\n",
    "data[categorical_columns] = categorical_imputer.fit_transform(data[categorical_columns])\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['location', 'size', 'total_sqft'], drop_first=True)\n",
    "\n",
    "# Preprocess the data and split into features and target\n",
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM regression model\n",
    "model = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using different regression metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the regression metrics\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R^2) Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d36db6-8743-4ac8-8406-790b2c1ef599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 15528.364797772449\n"
     ]
    }
   ],
   "source": [
    "#2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?\n",
    "\n",
    "#Ans\n",
    "\n",
    "#If your goal is to predict the actual price of a house as accurately as possible, the Mean Squared Error (MSE) would be a more appropriate evaluation metric compared to R-squared.\n",
    "\n",
    "#MSE measures the average squared difference between the predicted and actual values. It provides a measure of the average magnitude of the errors made by the model. In the context of predicting house prices, MSE indicates how close, on average, the predicted prices are to the actual prices. A lower MSE indicates better accuracy in predicting house prices.\n",
    "\n",
    "#R-squared, on the other hand, measures the proportion of the variance in the dependent variable (actual house prices) that is explained by the independent variables (features) in the model. It provides a measure of the goodness of fit of the model. While R-squared is a valuable metric for understanding the explanatory power of the model, it may not directly reflect the accuracy of individual price predictions. R-squared is more suitable when the focus is on understanding the relationships between variables rather than precise prediction accuracy.\n",
    "\n",
    "#Therefore, if your primary goal is to predict house prices as accurately as possible, you should evaluate the model using the MSE metric. Additionally, you can also consider other evaluation metrics such as mean absolute error (MAE) or root mean squared error (RMSE) to get a comprehensive understanding of the prediction accuracy.\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already prepared your feature matrix X and target variable y\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the SVM regression model\n",
    "model = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d2dee1-d949-4437-83ee-175af926087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?\n",
    "\n",
    "#Ans\n",
    "\n",
    "#When dealing with a dataset that contains a significant number of outliers, it is generally recommended to use evaluation metrics that are robust to outliers. In such cases, the mean absolute error (MAE) is a more appropriate regression metric compared to metrics such as mean squared error (MSE) or R-squared.\n",
    "\n",
    "#The reason is that MAE calculates the average absolute difference between the predicted and actual values, which is less sensitive to outliers compared to MSE. Outliers have a larger impact on MSE because it squares the differences between predicted and actual values, amplifying the effect of extreme values.\n",
    "\n",
    "#Therefore, when dealing with a dataset containing a significant number of outliers, it is advisable to use MAE as the evaluation metric for your SVM regression model. This will provide a more robust assessment of the model's performance by considering the absolute differences between predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501fccc4-838d-4dd4-a212-a4ba9305702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?\n",
    "\n",
    "#Ans\n",
    "\n",
    "#In this case, since the calculated values of Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are very close, either metric can be used to evaluate the performance of the SVM regression model with a polynomial kernel.\n",
    "\n",
    "#MSE measures the average squared difference between the predicted and actual values. It is widely used and provides a good overall assessment of the model's performance. RMSE is the square root of MSE and is useful when you want the evaluation metric to be in the same unit as the target variable. It also penalizes larger errors more heavily than MSE.\n",
    "\n",
    "#Ultimately, the choice between MSE and RMSE depends on the specific requirements and preferences of the problem at hand. Both metrics provide similar information about the model's performance, and the decision can be based on the context and ease of interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544ab1dd-773e-4294-aa0e-696622ec9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?\n",
    "\n",
    "#Ans\n",
    "\n",
    "#If the goal is to measure how well the model explains the variance in the target variable, the most appropriate evaluation metric would be the coefficient of determination, commonly known as R-squared (R^2). R-squared provides an indication of the proportion of variance in the target variable that is explained by the model.\n",
    "\n",
    "#R-squared takes values between 0 and 1, where a value of 0 indicates that the model does not explain any variance in the target variable, and a value of 1 indicates that the model perfectly explains all the variance. Therefore, a higher R-squared value indicates a better fit of the model to the data and a higher level of explanation of the variance.\n",
    "\n",
    "#When comparing SVM regression models with different kernels (linear, polynomial, and RBF), calculating and comparing the R-squared values for each model would allow you to determine which kernel performs better in terms of explaining the variance in the target variable. The model with the highest R-squared value would be considered the best in terms of capturing and explaining the variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81078eb-847f-4604-be6c-23174be1146c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
